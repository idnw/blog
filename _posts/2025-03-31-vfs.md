---
layout: post
title: VFS虚拟文件系统
subtitle: linux filesystem.
tags: [linux, fs]
---

# 核心数据结构

## inode

inode不包含文件名，文件名保存在所处的目录文件中（目录项），目录也是一种特殊的文件，也是由inode表示。目录项包含文件名或目录名， 以及文件或目录的inode编号。

软链接也是一个inode，它的内容只包含指向文件的指针，而不包括真实内容。删除目标内容，不会影响软链接文件。

硬链接文件的目录项，包含的inode与目标文件inode相同，这样inode的计数指针为2，删除目标文件或硬链接时将inode计数器减一，当减为0时才删除文件。

同一个进程多次打开同一个文件，会返回不同的文件描述符，并为每个fd创建一个file结构，每个file维护自己的偏移地址。

## super\_block

内存中的inode可能经过修改文件名、访问等操作变脏，需要通过超级块同步到硬件介质中。

## file

每个文件描述符都对应一个file，但可能都指向同一个inode。

## address\_space

## dentry

## file\_system\_type

不同的文件系统在file\_system\_type链表中只需注册一次，但每个不同的文件系统类型可以有多个挂载点，例如/root和/home在不同的分区，但都格式化为ext4文件系统类型。

# 根文件系统的挂载


```
start_kernel
    vfs_caches_init
        dcache_init  //创建dentry缓存
        inode_init  //创建inode缓存
        files_init  //创建file缓存
        mnt_init  //创建mount缓存
        ...
```

sysfs依赖kernfs，所以先调用kernfs\_init，才调用sysfs\_init，但sysfs不是必须的。

## shmem\_init的实现

TMPFS依赖SHMEM配置，tmpfs是一个基于内存的文件系统，文件内容要么在内存中，要么在swap空间中，umount该文件系统会释放所有内存，从而丢失数据。DEVTMPFS依赖于TMPFS，如果TMPFS没有实现，则DEVTMPFS基于更简单的RAMFS实现，devtmpfs挂载在/dev目录。

SHMEM是一个内部的文件系统，默认会开启，用于管理共享内存。也可以为用户态导出一个tmpfs（如果TMPFS使能），如果SHMEM没有编译，那么共享内存shmem和tmpfs会基于更简单的ramfs来实现。shmem可以swap，但ramfs没有swap。RAMFS是一定会编译的。

BLK\_DEV\_RAM是一个基于内存的块设备，可以像操作块设备一样，例如格式化一个文件系统，读写等。经常用于存储一个最小的根文件系统，用命令行参数ramdisk=XX来指定，但这种方式已经弃用了，所以一般不配置该选项。因为既然都是基于内存了，则完全可以绕开块层。

BLK\_DEV\_INITRD支持了initramfs/initrd，initramfs基于ramfs，作为默认的根文件系统，用于加载驱动和挂载最终的根文件系统。如果也开启了BLK\_DEV\_RAM，则支持initrd，initrd还依赖块层的接口。所以一般的配置是BLK\_DEV\_INITRD=y，因此编译的文件包括：initramfs.c、do\_mounts\_initrd.c，而不编译noinitramfs.c、do\_mounts\_rd.c、driver/block/brd.c。

第一个根文件系统rootfs是在`mnt_init->init_mount_tree`中创建的，基于内存，如果定义了TMPFS，则基于SHMEM实现，否则基于RAMFS实现。这个文件系统中只有/dev/console节点，并作为0号进程的根文件系统。进程0创建进程1后，由进程1从initramfs中挂载可以加载最终根文件系统的根文件系统。

populate\_rootfs的调用栈：
rest\_init创建的1号进程：
```
#0  populate_rootfs () at init/initramfs.c:761
#1  0xffffffff818eab7a in do_one_initcall (fn=0xffffffff818ebf5d <populate_rootfs>) at init/main.c:1245
#2  0xffffffff818eadc6 in do_initcall_level (command_line=0xffff88800014b120 "console", level=5) at ./include/linux/compiler.h:231
#3  do_initcalls () at init/main.c:1323
#4  do_basic_setup () at init/main.c:1342
#5  kernel_init_freeable () at init/main.c:1555
#6  0xffffffff8128a73a in kernel_init (unused=unused@entry=0x0 <fixed_percpu_data>) at init/main.c:1444
#7  0xffffffff8101fb1b in ret_from_fork (prev=&lt;optimized out&gt;, regs=0xffffc9000000bf58, fn=0xffffffff8128a725 <kernel_init>,
fn_arg=0x0 <fixed_percpu_data>) at arch/x86/kernel/process.c:147
#8  0xffffffff81000a01 in ret_from_fork_asm () at arch/x86/entry/entry_64.S:244
#9  0x0000000000000000 in ?? ()
```
但`do_populate_rootfs`是由`populate_rootfs`异步执行的：然后在1号进程中等待根文件系统创建完成：`kernel_init_freeable->wait_for_initramfs`。异步机制是在kernel/async.c中实现的，本质是一个workqueue，2号进程会扫描链表，并创建一个内核线程去执行它。看起来在initramfs之前，还有一个更小的根文件系统，名为rootfs已经挂载。

# 自由问题

## 为什么页缓存打开的文件，在/proc/\$pid/maps中没有相关的段？

页缓存是由内核管理，不属于进程的虚拟地址空间，如果将打开的文件fd用mmap映射到进程虚拟地址空间，那么可以在/proc/\$pid/maps中看到。进程的maps中的段是进程主动进行映射的，而页缓存对进程来说是透明的，内核为了加速文件的io进行的优化。

## inode如何统一各种文件类型？

文件的类型有7种：socket、链接文件、普通文件、目录文件、块设备文件、字符设备文件、管道文件，inode->i\_mode成员表示文件的类型。不同的文件类型，需要提供不同的inode->i\_fop，用于操作这类设备，例如tmpfs文件系统上的文件：
普通文件：inode->i\_fop = \&shmem\_file\_operations;
目录文件：inode->i\_fop = \&simple\_offset\_dir\_operations;
字符设备：inode->i\_fop = \&def\_chr\_fops;
块设备：inode->i\_fop = \&def\_blk\_fops;
管道文件：inode->i\_fop = \&pipefifo\_fops;
链接文件：
socket文件：

在`vfs_open-> do_dentry_open`打开文件的时候，会给`file->f_op = inode->i_fop`。然后调用fop->open (inode, file)，如果该inode作为特殊文件也实现了自己的fop，那么会将file->fop替换为具体实现的版本：例如字符设备默认的fop为def\_chr\_fops，但不同的字符设备的操作是不一样的，所以最终会把file->ops替换为inode->i\_cdev->ops，而不是替换inode->i\_fop，因为新打开的文件还要通过inode中转。字符设备的版本是在cdev\_init时设置，其他的特殊文件没有自定义版本。
inode的union结果也会指向它所属的具体文件：
```
union {
struct pipe_inode_info	*i_pipe;  //管道文件
struct cdev		*i_cdev;  //字符设备
char			*i_link;  //链接文件
};
```
## inode从哪来，静态创建or动态创建？

任何一个文件（包括目录文件、普通文件、链接文件、管道等等），总是在一个目录下创建，也总是在一个目录下删除、重命名、修改属性等等，所以，这些操作本质上都是基于当前目录（该目录的inode）发起，例如在当前目录下执行mkdir、mknod、mkfifo、ln、touch/vi、rm、mv这些命令，最终会到达该目录的inode的操作接口上，而目录又必然属于某一个文件系统，不同文件系统的目录inode操作接口不同，以tmpfs为例，目录inode的操作接口实现为：
```
static const struct inode_operations shmem_dir_inode_operations = {
    .getattr	= shmem_getattr,
    .create		= shmem_create,
    .lookup		= simple_lookup,
    .link		= shmem_link,
    .unlink		= shmem_unlink,
    .symlink	= shmem_symlink,
    .mkdir		= shmem_mkdir,
    .rmdir		= shmem_rmdir,
    .mknod		= shmem_mknod,
    .rename		= shmem_rename2,
    .tmpfile	= shmem_tmpfile,
    .get_offset_ctx	= shmem_get_offset_ctx,
    ……
};
```
普通文件的inode操作接口则简单许多，仅包含属性设置、重命名等，因为你无法在一个普通文件上创建文件。

```
static const struct inode_operations shmem_inode_operations = {
.getattr	= shmem_getattr,
.setattr	= shmem_setattr,
……
};
```


在打开文件或创建文件时，最终调用到：
```
inode_operations
    .mknod/symlink/tmpfile
        shmem_get_inode
            __shmem_get_inode
                new_inode(super_block)
                    new_inode_pseudo
                        alloc_inode
```
`alloc_inode`要么调用`super_operations.alloc_inode`，从shmem的slab缓存shmem\_inode\_cachep中申请，要么从全局slab缓存inode\_cachep中获得一个。shmem\_inode\_cachep是在`vfs_caches_init->mnt_init->shmem_init->shmem_init_inodecache`时创建，而inode\_cachep是在`start_kernel->vfs_caches_init->inode_init`时创建。

inode申请之后，又会初始化这个inode的i\_op和i\_fop，即inode本身的操作以及这类文件的操作。

## inode、fd、file如何绑定？
```
do_sys_open
    do_sys_openat2
        get_unused_fd_flags  //从task_struct->files->fdt中找到一个空闲的fd；
        do_filp_open
        fd_install
```

`do_filp_open`通过查找path找到inode，调用inode->open打开文件，并返回一个struct  file实例，将inode的相关信息保存在file中，供后续应用程序调用read/write；
`fd_install`将fd和file实例绑定，即插入fdt->fd\[fd]数组。

上述过程执行后：
file->f\_inode = inode
file->f\_op = inode->i\_fop
file->f\_mapping = inode->i\_mapping

## mmap

对于文件映射来说，file\_operations实现了mmap (struct file \*file, struct vm\_area\_struct \*vma)接口，不同的文件都有各自的实现，但最终都会给参数vma-> vm\_ops赋值一个vm\_operations\_struct实例，例如：
- 普通文件：`vma->vm_ops = &generic_file_vm_ops;`
- 基于内存的设备文件：`vma->vm_ops = &shmem_anon_vm_ops;`
- vhost\_vdpa设备：`vma->vm_ops = &vhost_vdpa_vm_ops;`

这些vm\_operations\_struct实例最常用的成员函数为.fault和map\_pages，用于在缺页中断发生后执行，map\_pages优先于fault执行。上述三个文件如果发生缺页时，最终会调用：
- 普通文件：`filemap_fault`，从磁盘中读取数据；
- 基于内存的设备文件：`filemap_fault`，从基于内存的文件系统中读取数据；
- vhost\_vdpa：`vhost_vdpa_fault`，建立用户态和内核态的映射。

vma-> vm\_ops为NULL的映射为匿名映射，直接分配内存页，并设置页表，建立逆向映射。

## address\_space

基于文件的读写，无论是直接调用vfs的read/write还是mmap后在缺页中断中按需调页，最终都会通过该inode->address\_space->a\_ops读写数据后端。每个address\_space都是属于一个指定的inode，即inode->i\_data。通过address\_space ->i\_mmap管理了所有映射到该inode的vma，该结构用于逆向映射，作用类似于匿名映射的anon\_vma，当一个page用于基于文件的缓存时，page-> mapping可以基于此找到所有的vma，进而找到所有的进程，从而修改页表，如果是匿名映射，则page->mapping指向一个anon\_vma实例。

